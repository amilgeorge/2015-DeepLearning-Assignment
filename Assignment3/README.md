Assignment 3
=============

Problem 14
-----------
Neural network is implemented in the file - NeuralNetwork.py
Gradient Descent with mini batches is implemented in the file - gradient_descent_trainer.py
RMSPRop is implemented in the file - rms_prop_trainer.py

Early stopping condition is used to stop training when the validation error 

L1, L2 regularization are implemented as part of the cost function in training algorithm
Dropout implemented in the NeuralNetwork drops the weights according to dropout_rate

Problem 15
-----------
Folder __Observations/2015-05-30 19:35:24__ contains the error curves generated with tanh activation and 300 hidden units


Problem 16
----------
The choice of weight initialization is dependent on the activation function used because we want the gradients to be maximum in the begining

The graph Observations/activation_comparison.png shows a comparison of training errors over each iteration with different activation functions

Problem 17
----------
Each successful execution creates the plot error.png in the directory named with the current timestamp.

Problem 18
-----------

Each successful execution creates the plot repFields.png in the directory named with the current timestamp.

Problem 19
-----------

Usage
======

Neural Network
---------------
Implementation of 






Folder Structure
=================

__/src__             - Contains all the source code

__/Observations__ - Each run creates a floder with a new timestamp and contains observations and plots generated by the run

__/data__            - Contains the data

All python root executables start with the name "main_*".py

